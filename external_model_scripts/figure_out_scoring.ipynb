{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86289f2e-f60d-451a-b0cc-8e6e79c7ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring data saved to project's Domino Dataset\n",
      "Ground truth data saved to project's Domino Dataset\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.datasets import load_iris\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import uuid\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# UPDATE: Your Model Parameters\n",
    "external_datasource = \"demo-bucket\"\n",
    "datasourceType = \"s3\"\n",
    "DMM_datasource_name = \"se-demo-bucket\"\n",
    "domino_url = \"demo2.dominodatalab.com\"\n",
    "DMM_model_id = \"6628103c965e21e5b0d56b29\"\n",
    "\n",
    "# Today's date\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day - 1\n",
    "year = date.year\n",
    "\n",
    "# Load data for scoring\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data = data['data'], columns = data.feature_names)\n",
    "df['variety'] = data['target']\n",
    "\n",
    "scoring_data = df[data.feature_names].copy()\n",
    "\n",
    "# Jitter the scoring data\n",
    "for row in scoring_data.iterrows():\n",
    "    for c in scoring_data.columns:\n",
    "        scoring_data[c] = np.maximum(0.1, scoring_data[c] + np.random.normal()/25)\n",
    "\n",
    "# Load the \"external\" model\n",
    "file_name = \"/mnt/code/models/xgb_iris.pkl\"\n",
    "model = pickle.load(open(file_name, \"rb\"))\n",
    "\n",
    "# Get model predictions (numeric)\n",
    "scoring_data = scoring_data.values.tolist()\n",
    "model_predictions = model.predict(scoring_data)\n",
    "\n",
    "# Create the scoring dataset for model moniotring\n",
    "\n",
    "# Data that was scored, model predictions (as strings), timestamp and event ID for model qulaity monitoring.  \n",
    "predictions = pd.DataFrame(scoring_data, columns=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)' ])\n",
    "predictions['predictions'] = model_predictions\n",
    "predictions['variety'] = [data.target_names[y] for y in predictions['predictions']]\n",
    "predictions.drop('predictions', axis=1, inplace=True)\n",
    "predictions['timestamp']= datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "event_ids = [uuid.uuid4() for x in range(predictions.shape[0])]\n",
    "predictions['event_id'] = event_ids\n",
    "\n",
    "# Save version to Domino Dataset for future reference\n",
    "predictions.to_csv('/mnt/data/{}/external_iris_scoring_data_{}_{}_{}.csv'.format(os.environ.get('DOMINO_PROJECT_NAME'), month, day, year), index=False)\n",
    "\n",
    "print(\"Scoring data saved to project's Domino Dataset\")\n",
    "\n",
    "# Create the \"dummy\" ground truth dataset\n",
    "\n",
    "ground_truth = pd.DataFrame(columns=['event_id', 'iris_ground_truth'])\n",
    "ground_truth['event_id'] = predictions['event_id']\n",
    "ground_truth['iris_ground_truth'] = predictions['variety']\n",
    "\n",
    "# These row labels help find some diferent iris types in our initial scoring data\n",
    "end_index = predictions.shape[0]\n",
    "mid_index = int(round(predictions.shape[0] / 2, 0))\n",
    "\n",
    "# Simulate some classifcation errors. This makes our confusion matrix interesting.\n",
    "ground_truth.iloc[0, 1] = 'virginica'\n",
    "ground_truth.iloc[1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index-1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index, 1] = 'virginica'\n",
    "ground_truth.iloc[end_index-2, 1] = 'setosa'\n",
    "ground_truth.iloc[end_index-1, 1] = 'setosa'\n",
    "\n",
    "# Save each version locally \n",
    "ground_truth.to_csv('/mnt/data/{}/external_iris_ground_truth_{}_{}_{}.csv'.format(os.environ.get('DOMINO_PROJECT_NAME'), month, day, year), index=False)\n",
    "\n",
    "print(\"Ground truth data saved to project's Domino Dataset\")\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eaadf81-8d2f-48e1-95b3-2e3f670a1cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.datasets import load_iris\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import uuid\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# UPDATE: Your Model Parameters\n",
    "external_datasource = \"demo-bucket\"\n",
    "datasourceType = \"s3\"\n",
    "DMM_datasource_name = \"se-demo-bucket\"\n",
    "domino_url = \"demo2.dominodatalab.com\"\n",
    "DMM_model_id = \"6628103c965e21e5b0d56b29\"\n",
    "\n",
    "# Today's date\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day - 1\n",
    "year = date.year\n",
    "\n",
    "# Load data for scoring\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data = data['data'], columns = data.feature_names)\n",
    "df['variety'] = data['target']\n",
    "\n",
    "scoring_data = df[data.feature_names].copy()\n",
    "scoring_data\n",
    "# predictions_df.to_csv('/mnt/code/data/external_model_scoring_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc2febe3-6a4c-42b5-bc5a-87e3421849c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering external_iris_scoring_data_4_23_2024.csv from demo-bucket data source in DMM\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# UPDATE: Your Model Parameters\n",
    "external_datasource = \"demo-bucket\"\n",
    "datasourceType = \"s3\"\n",
    "DMM_datasource_name = \"se-demo-bucket\"\n",
    "domino_url = \"demo2.dominodatalab.com\"\n",
    "DMM_model_id = \"6628103c965e21e5b0d56b29\"\n",
    "\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# Today's date\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day -1\n",
    "year = date.year\n",
    "\n",
    "# Today's scoring file name\n",
    "scoring_file_name = \"external_iris_scoring_data_{}_{}_{}.csv\".format(month, day, year)\n",
    "\n",
    "# Today's ground truth file name\n",
    "gt_file_name = \"external_iris_ground_truth_{}_{}_{}.csv\".format(month, day, year)\n",
    "\n",
    "# Upload scoring data to DMM data source using a Domino data source (s3 in this example)\n",
    "\n",
    "# instantiate a client and fetch the datasource instance\n",
    "object_store = DataSourceClient().get_datasource(\"{}\".format(external_datasource)) # Update\n",
    "\n",
    "# Upload scoring and ground truth data to monitoring data source\n",
    "object_store.upload_file(scoring_file_name, '/mnt/data/{}/{}'.format(os.environ.get('DOMINO_PROJECT_NAME'), scoring_file_name))\n",
    "object_store.upload_file(gt_file_name, '/mnt/data/{}/{}'.format(os.environ.get('DOMINO_PROJECT_NAME'), gt_file_name))\n",
    "\n",
    "# Update scoring and ground truth file paths with model monitoring API\n",
    "\n",
    "# This step only updates the file paths, and assumes the external model has already been registered in DMM! See \"External_DMM_Quickstart.ipynb\"\n",
    "\n",
    "print('Registering {} from {} data source in DMM'.format(scoring_file_name, external_datasource))\n",
    "\n",
    "scoring_data_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/prediction\".format(domino_url, DMM_model_id)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    " \n",
    "scoring_data_payload = \"\"\"\n",
    "{{\n",
    "    \"datasetDetails\": {{\n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"{2}\"\n",
    "        }}\n",
    "}}\n",
    "\"\"\".format(scoring_file_name, DMM_datasource_name, datasourceType)\n",
    " \n",
    "# Make api call\n",
    "scoring_data_response = requests.request(\"PUT\", scoring_data_url, headers=headers, data = scoring_data_payload)\n",
    " \n",
    "# Print response\n",
    "print(scoring_data_response.text.encode('utf8'))\n",
    "\n",
    "# print('Registering {} from {} data source in DMM'.format(gt_file_name, external_datasource))\n",
    "\n",
    "# ground_truth_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(domino_url, DMM_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c296c0-a258-41ce-9da2-51722e9ec4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
