{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c01e6a6-9c77-473d-a1f5-d7e2f427df76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Integrated Model with Domino Model Monitoring\n",
    "\n",
    "Example notebook to set up integrated Domino Model Monitoring:\n",
    "Model monitoring from a Domino Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2181e090-d398-4644-b0e8-a4082611ed78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcc03e-4091-42af-9963-e26453600484",
   "metadata": {},
   "source": [
    "### Train a simple xgboost model on the Iris dataset\n",
    "\n",
    "Feel free to swap out the iris dataset for any other dataset. If you pick a different dataset, be sure to update the ground truth dataset used in the final step to match your dataset's target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144b19f7-ebc5-4dd0-af72-98e24c527eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"data\"], data[\"target\"], test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1b6d-ecce-4c7b-8281-9a71a3495707",
   "metadata": {},
   "source": [
    "### Register the Training Dataset\n",
    "\n",
    "This is the reference baseline for Drift. It will be automatically ingested when Model Monitoring is configured \n",
    "in the Model Monitoring API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffd2be1-4a18-420e-945d-d319442a5547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSetVersion iris_python_multi_classification_DMM-Quickstart:10\n"
     ]
    }
   ],
   "source": [
    "from domino_data.training_sets import client, model\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "target_column_name = \"variety\"\n",
    "\n",
    "training_df = pd.DataFrame(data = X_train, columns = data.feature_names)\n",
    "training_df[target_column_name] = [data.target_names[y] for y in y_train]\n",
    "\n",
    "tsv = client.create_training_set_version(\n",
    "    training_set_name=\"iris_python_multi_classification_{}\".format(os.environ.get('DOMINO_PROJECT_NAME')),\n",
    "    df=training_df,\n",
    "    key_columns=[],\n",
    "    target_columns=[target_column_name],\n",
    "    exclude_columns=[],\n",
    "    meta={\"experiment_id\": \"0.1\"},\n",
    "    monitoring_meta=model.MonitoringMeta(**{\n",
    "        \"categorical_columns\": [target_column_name],\n",
    "        \"timestamp_columns\": [],\n",
    "        \"ordinal_columns\": []\n",
    "    })\n",
    ")\n",
    "\n",
    "print(f\"TrainingSetVersion {tsv.training_set_name}:{tsv.number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75bb5df6-2a9e-4564-9faf-cec713a3232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally for reference\n",
    "training_df.to_csv(\"data/iris_train_data.csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2db7f-89b7-4646-92d7-6aae3bf69315",
   "metadata": {},
   "source": [
    "### Train the Iris Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0815351c-c786-4e22-8d2c-8284d288c6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from domino_data_capture.data_capture_client import DataCaptureClient\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    learning_rate=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "# train model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Optional, save the serialized model locally \n",
    "# file_name = \"models/xgb_iris.pkl\"\n",
    "# pickle.dump(xgb_classifier, open(file_name, \"wb\"))\n",
    "\n",
    "data_capture_client = DataCaptureClient(data.feature_names, [target_column_name])\n",
    "\n",
    "class IrisModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, context, model_input, params=None):\n",
    "        event_time = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "        prediction = self.model.predict(model_input)\n",
    "        \n",
    "        for i in range(len(prediction)):\n",
    "            # Record eventID and current time\n",
    "            event_id = uuid.uuid4()\n",
    "            # Convert np types to python builtin type to allow JSON serialization by prediction capture library\n",
    "            model_input_value = [float(x) for x in model_input[i]]\n",
    "            prediction_value = [data.target_names[prediction[i]]]\n",
    "            \n",
    "            # Capture this prediction event so Domino can keep track\n",
    "            data_capture_client.capturePrediction(model_input_value, prediction_value, event_id=event_id,\n",
    "                                timestamp=event_time)\n",
    "        return prediction\n",
    "\n",
    "model = IrisModel(xgb_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2909a-85cc-4c80-9db3-28a77867e22b",
   "metadata": {},
   "source": [
    "### Register your Model in the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854c970b-34b5-4747-8d10-a982f80a0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'DMM-Quickstart-Model' already exists. Creating a new version of this model...\n",
      "2024/04/24 00:30:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: DMM-Quickstart-Model, version 5\n",
      "Created version '5' of model 'DMM-Quickstart-Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.model.ModelInfo object at 0x7f28606f8970>\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"DMM-Quickstart-Model\", # A unique name\n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model\"\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d4cf1-a730-435f-a288-4de65f025997",
   "metadata": {},
   "source": [
    "### Create Model API from the Model Card\n",
    "\n",
    "Once your model has been registered:\n",
    "\n",
    "1) Navigate to the model registry, open the Model Card for \"DMM-Quickstart-Model\" (or whatever you called your model), and create a new Model API. \n",
    "\n",
    "2) For Model API Source, select \"Choose Model From Model Registry\" and select \"DMM-Quickstart-Model\"\n",
    "\n",
    "3) Once the Model API is green and says \"Running\", navigate to the \"Configure Model Monitoring\" tab in the Model API. On the right, click \"Configure Monitoring\", and follow the instructions. Select your training set created above as the model baseline for drift, and set the model type to Classification.\n",
    "\n",
    "4) Score some data, using the sample Python code below. Be sure to update your URL and auth token to point to your Model API. A sample specific to your model is available in the Model API Overview tab. Domino Prediction Data Capture will capture these predictions in the back end.\n",
    "\n",
    "![alt text](readme_images/API_Request_Python.png)\n",
    "\n",
    "6) Wait for a bit. If you navigate to Domino Model Monitoring, the new model will appear. If you click into your new monitored model, under \"Overview\" in the \"Ingest History\" tab, the training data should be shown as ingested and \"Done\". However, under \"Data Drift\", your model will still say \"No Prediction Data Added\" for about an hour. The Model API Monitoring tab will say \"Waiting for Prediction Data.\" The prediction data from step 4 has been captured, but you have to wait for the first automated ingest for that drift data to appear in the Model Monitoring UI and to move to the next steps.\n",
    "\n",
    "7) Once data drift ingestion has happened, a new Domino Dataset called \"prediction_data\" will appear in your Project Domino Datasets list, and the Model Monitoring Data Drift section will populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe56a962-7d9f-4a18-b8f6-f14b50417ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Date': 'Wed, 24 Apr 2024 00:33:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '241', 'Connection': 'keep-alive', 'X-Request-ID': '6YSGA2HUFZB9CTJ7', 'Domino-Server': 'nginx-ingress,model-api,', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'POST', 'Access-Control-Allow-Headers': 'authorization,content-type', 'Content-Security-Policy': \"frame-ancestors 'self' demo2.dominodatalab.com; \", 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'X-Frame-Options': 'SAMEORIGIN always'}\n",
      "{'model_time_in_ms': 7, 'release': {'harness_version': '0.1', 'registered_model_name': 'DMM-Quickstart-Model', 'registered_model_version': '1'}, 'request_id': '6YSGA2HUFZB9CTJ7', 'result': [0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2], 'timing': 7.050275802612305}\n"
     ]
    }
   ],
   "source": [
    "# Update this to call your URL and Auth Token. Snippet avaialble from Model API Overview.\n",
    "# This reference example uses a User Environment Variable to secure the Model API and Auth token.\n",
    "# If you choose to use environment variables (recommended with git-based projects), you'll need to save and restart the workspace once they are created.\n",
    "\n",
    "model_url = os.environ.get('MODEL_URL')\n",
    "model_auth_token = os.environ.get('MODEL_AUTH_TOKEN')\n",
    "\n",
    "import requests\n",
    " \n",
    "response = requests.post(model_url, # Update\n",
    "    auth=(\n",
    "            model_auth_token, # Update\n",
    "            model_auth_token # Update\n",
    "    ),\n",
    "    json={\n",
    "       \"data\":  [  [4.3, 3. , 1.1, 0.1],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [6.7, 3. , 5.2, 2.3],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],]\n",
    "    }\n",
    ")\n",
    " \n",
    "print(response.status_code)\n",
    "print(response.headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a23c65-10c7-4217-80ab-1848f7a50b8a",
   "metadata": {},
   "source": [
    "### Create a Dummy Ground Truth Dataset\n",
    "\n",
    "Typically for this step you would fetch actual ground truth data (the actual outcomes from what your model predicted on), \n",
    "join the actual outcomes with your prediction data, and upload into a datasource attached to model monitoring for Model Quality \n",
    "analysis.\n",
    "\n",
    "However, for purposes of creating a quick demo, we'll make up some fake ground truth data using the model predictions captured with Domino's\n",
    "data capture client. These predictions are stored in an automatically-generated Domino Dataset called \"prediction_data\"\n",
    "\n",
    "Once Data has ingested (roughly one hour), a \"prediction_data\" Domino Dataset will be added to the Project.\n",
    "\n",
    "1) Navigate to the Domino Dataset Folder on the left (back from /mnt/ , then \"data/prediction_data/...\")\n",
    "Copy the path to read in your registered model predictions.\n",
    "\n",
    "2) Join the Predictions to make your ground truth dataset, shuffle some labels to simulate classification errors, and save the ground truth csv\n",
    "\n",
    "3) Upload the csv to the s3 bucket attached as a Domino Model Monitoring Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26602162-e1c8-4563-9632-90d291020079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Navigate to the most recent predictions and copy the file path to one of the parquet files in there. \n",
    "# This is where you can find data captured by the Data Capture Client in your Model API\n",
    "\n",
    "# /mnt/data/prediction_data/{PREDICTION_DATA_ID}/{DATE}/{TIME}/predictions_{ID}.parquet\n",
    "\n",
    "path = '/mnt/data/prediction_data/65b04f6b1266902edb95b260/$$date$$=2024-04-23Z/$$hour$$=07Z/predictions_96f154f9-99c3-4da0-ae7c-878b21ddffa7.parquet'\n",
    "\n",
    "predictions = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17981520-45e2-4c06-9b06-6088bffeb897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>__domino_timestamp</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952155</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>4.561468</td>\n",
       "      <td>2.657454</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-04-23 07:03:15.704713+00:00</td>\n",
       "      <td>2024-04-23T07:03:15.708669+00:00</td>\n",
       "      <td>be236532-24d4-4c38-b3c2-2cb5bc8e8ef6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952155</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>4.361468</td>\n",
       "      <td>2.157454</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-04-23 07:03:15.704713+00:00</td>\n",
       "      <td>2024-04-23T07:03:15.709058+00:00</td>\n",
       "      <td>8375631a-7f89-4f6f-8e01-b880464ba46b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.852155</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>4.161468</td>\n",
       "      <td>2.357454</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-04-23 07:03:15.704713+00:00</td>\n",
       "      <td>2024-04-23T07:03:15.709294+00:00</td>\n",
       "      <td>f5b8ed3f-d52d-427e-9797-ebc7605f3ecc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052155</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>4.061468</td>\n",
       "      <td>2.257454</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-04-23 07:03:15.704713+00:00</td>\n",
       "      <td>2024-04-23T07:03:15.709519+00:00</td>\n",
       "      <td>98751350-0a1d-4d12-bc56-4015962f2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952155</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>4.461468</td>\n",
       "      <td>2.757454</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-04-23 07:03:15.704713+00:00</td>\n",
       "      <td>2024-04-23T07:03:15.709734+00:00</td>\n",
       "      <td>30560aed-fe09-4ee9-8623-d23b16f5b42e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal length (cm)  petal width (cm)  sepal length (cm)  sepal width (cm)  \\\n",
       "0           0.952155          0.351034           4.561468          2.657454   \n",
       "1           0.952155          0.351034           4.361468          2.157454   \n",
       "2           0.852155          0.351034           4.161468          2.357454   \n",
       "3           1.052155          0.351034           4.061468          2.257454   \n",
       "4           0.952155          0.351034           4.461468          2.757454   \n",
       "\n",
       "  variety                        timestamp                __domino_timestamp  \\\n",
       "0  setosa 2024-04-23 07:03:15.704713+00:00  2024-04-23T07:03:15.708669+00:00   \n",
       "1  setosa 2024-04-23 07:03:15.704713+00:00  2024-04-23T07:03:15.709058+00:00   \n",
       "2  setosa 2024-04-23 07:03:15.704713+00:00  2024-04-23T07:03:15.709294+00:00   \n",
       "3  setosa 2024-04-23 07:03:15.704713+00:00  2024-04-23T07:03:15.709519+00:00   \n",
       "4  setosa 2024-04-23 07:03:15.704713+00:00  2024-04-23T07:03:15.709734+00:00   \n",
       "\n",
       "                               event_id  \n",
       "0  be236532-24d4-4c38-b3c2-2cb5bc8e8ef6  \n",
       "1  8375631a-7f89-4f6f-8e01-b880464ba46b  \n",
       "2  f5b8ed3f-d52d-427e-9797-ebc7605f3ecc  \n",
       "3  98751350-0a1d-4d12-bc56-4015962f2375  \n",
       "4  30560aed-fe09-4ee9-8623-d23b16f5b42e  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36478b4f-53de-4a11-879e-b7a82875a892",
   "metadata": {},
   "source": [
    "The Ground Truth dataset needs 2 columns: \n",
    "\n",
    "1) The existing event ID column from the model predictions.\n",
    "   \n",
    "    This column has the join keys for joing ground truth lables to your model's predictions\n",
    "\n",
    "3) Your new column containing ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0abbad2-3785-4cc8-b10c-608bc82ecfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_id = predictions['event_id']\n",
    "iris_ground_truth = predictions['variety']\n",
    "\n",
    "# Create a new dataframe\n",
    "ground_truth = pd.DataFrame(columns=['event_id', 'iris_ground_truth'])\n",
    "ground_truth['event_id'] = event_id\n",
    "ground_truth['iris_ground_truth'] = iris_ground_truth\n",
    "\n",
    "# These row labels help find some diferent iris types in our initial scoring data\n",
    "end_index = predictions.shape[0]\n",
    "mid_index = int(round(predictions.shape[0] / 2, 0))\n",
    "\n",
    "# Simulate some classifcation errors. This makes our confusion matrix interesting.\n",
    "ground_truth.iloc[0, 1] = 'virginica'\n",
    "ground_truth.iloc[1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index-1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index, 1] = 'virginica'\n",
    "ground_truth.iloc[end_index-2, 1] = 'setosa'\n",
    "ground_truth.iloc[end_index-1, 1] = 'setosa'\n",
    "\n",
    "# Save this example ground truth csv to your file to your Project files for reference.\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day\n",
    "year = date.year\n",
    "\n",
    "date = str(datetime.datetime.today()).split()[0]\n",
    "\n",
    "ground_truth.to_csv('data/iris_ground_truth_{}_{}_{}.csv'.format(month, day, year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f80dd9-4bc3-45a5-a39e-58363fa45adc",
   "metadata": {},
   "source": [
    "### Upload the ground truth file to a Domino Model Monitoring data source.\n",
    "\n",
    "Ground truth labels must come from an external data source attached to Domino Model Monitoring. The Model API does not capture ground truth labels, since they typically become avaiable after the prediction.\n",
    "\n",
    "The AWS example uses a Domino Data Source, you could also use boto3 or other methods to updload data to s3.\n",
    "\n",
    "The Azure example uses a Domino Data Source with ADLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d7d91-b77a-4c67-94c4-cda5e12e9680",
   "metadata": {},
   "source": [
    "#### AWS: s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e3e5cb-18de-41ab-a5a4-acdb85b49d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For this approach, add an s3 Domino Datasource bucket to your Project. Then, copy the first fe linwes of the automatically generated Python code.\n",
    "\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# instantiate a client and fetch the datasource instance\n",
    "object_store = DataSourceClient().get_datasource(\"demo-bucket\") # Update\n",
    "\n",
    "# list objects available in the datasource\n",
    "objects = object_store.list_objects()\n",
    "\n",
    "object_store.upload_file(\"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year), \"data/iris_ground_truth_{}_{}_{}.csv\".format(month, day, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd0908-c896-4f36-8a95-6ba34abac514",
   "metadata": {},
   "source": [
    "#### Azure: ADLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32068724-fb79-4ce3-a4e1-58fdff902bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# instantiate a client and fetch the datasource instance\n",
    "object_store = DataSourceClient().get_datasource(\"adlsdatasource\")\n",
    "\n",
    "# list objects available in the datasource\n",
    "objects = object_store.list_objects()\n",
    "\n",
    "object_store.upload_file(\"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year), \"data/iris_ground_truth_{}_{}_{}.csv\".format(month, day, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2b209-3d0e-41a8-96ff-5e2e70900356",
   "metadata": {},
   "source": [
    "### Add a Domino Datasource to Domino Model Monitoring\n",
    "\n",
    "In Domino Model Monitoring, if you have not already done so, add a Monitoring Data Source (in this example, an s3 bucket).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6b059-5c41-43dc-9526-ae6ece5f4787",
   "metadata": {
    "tags": []
   },
   "source": [
    "### First Time Registration of Ground Truth Labels via the API\n",
    "\n",
    "The final step is to register Ground Truth Labels with Domino Model Monitoring.\n",
    "\n",
    "This can be done in the Model Monitoring UI using the Ground Truth Config file, or using the Domino Model Monitoring API.\n",
    "\n",
    "Documentation here: https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_registerDatasetConfig\n",
    "\n",
    "You’ll need the following:\n",
    "\n",
    "1) The name of the monitoring data source you registered in Domino Model Monitoring (the name in Domino, not the s3 bucket name if they’re different).\n",
    "\n",
    "2) The Domino Model Monitoring Model ID, not the Model API model ID. This mode ID can be found in the Overview tab of your monitored model, or in the URL for that model.\n",
    "\n",
    "3) Your Domino API Key. Note that Domino Model Monitoring API keys have been deprecated, there is now only one API key for your whole Domino account.\n",
    "\n",
    "     *If this is your first time using your Domino API key, go to the Domino Workbench, then open up your User Account setting in the lower left. Regenerate your API key, save it securely, then also save to your Domino account as a User Environment Variable. In this example, I’ve called it “MY_API_KEY'. These are accessed & added under  “API Key” and “User Environment Variables” in your Account Settings.\n",
    "    Your Workspace will not yet know about your new User Environment Variable. Save your notebook, then save and restart your Workspace to make your workspace aware of the new environment variable.*\n",
    "    \n",
    "4) The path to your ground truth labels csv file in your monitoring data source (s3 in this case)\n",
    "\n",
    "5) The column name of your new, ground truth labels \n",
    "\n",
    "6) Your original target (or prediction) column name\n",
    "\n",
    "7) Your organization's Domino url to create the Domino Model Monitoring API endpoint.\n",
    "\n",
    "    For Example:\n",
    "    \n",
    "    “demo2.dominodatalab.com” to “my-domino-domain.dominodatalab.com”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e75973-c2f9-429e-aa4e-b8b1c029aaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering iris_ground_truth_1_25_2024.csv From S3 Bucket in DMM\n",
      "b'[\"Dataset already registered with the model.\"]'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    " \n",
    "# UPDATE: (1) The name of your monitoring data source in Domino Model Monitoring\n",
    "data_source = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID (NOT Model API model ID)\n",
    "model_id='65b0525c54ac3acc8cb495d1'\n",
    "\n",
    "# UPDATE: (3) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    " \n",
    "# UPDATE: (4) The name of the file uploaded to s3 above\n",
    "gt_file_name = \"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year)\n",
    "\n",
    "# UPDATE: (5) Ground Truth column name\n",
    "GT_column_name = 'iris_ground_truth'\n",
    "\n",
    "# UPDATE: (6) Your original target column name\n",
    "target_column_name = 'variety'\n",
    "\n",
    "# UPDATE: (7) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (8) Your DataSource Type\n",
    "datasource_type = \"s3\"\n",
    "\n",
    "ground_truth_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(your_domino_url, model_id)\n",
    "\n",
    "print('Registering {} From S3 Bucket in DMM'.format(gt_file_name))\n",
    " \n",
    "# create GT payload    \n",
    " \n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    " \n",
    "ground_truth_payload = \"\"\"\n",
    "{{\n",
    "    \"variables\": [{{\n",
    "    \n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"ground_truth\",\n",
    "            \"name\": \"{2}\", \n",
    "            \"forPredictionOutput\": \"{3}\"\n",
    "        \n",
    "    }}],\n",
    "    \"datasetDetails\": {{\n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"{4}\"\n",
    "        }}\n",
    "}}\n",
    "\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name, datasource_type)\n",
    " \n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", ground_truth_url, headers=headers, data = ground_truth_payload)\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc660f-f094-4b83-bc2a-935b835e9c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "Going forward, Domino will automatically capture all prediction data going across your Model API. It will ingest these predictions for Drift detection once per day. You can set a schedule to determine when this ingest happens.\n",
    "\n",
    "To periodically upload ground truth labels, repeat the previous step, but without the “variables” in the ground truth payload (this only needs to be done once). As new ground truth labels are added, point Domino to the path to the new labels in the monitoring data source by pinging the same Model Monitoring API:\n",
    "\n",
    "ground_truth_payload = \"\"\"\n",
    "\n",
    "{{\n",
    "\n",
    "       \"datasetDetails\": {{\n",
    "        \n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"s3\"\n",
    "        }}\n",
    "}}\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd486-42bb-48e7-85e5-2d4ed3056f18",
   "metadata": {},
   "source": [
    "### Automation with Domino Jobs\n",
    "To simulate Domino Model Monitoring over time, you can try out running the following two scripts as scheduled Domino Jobs:\n",
    "\n",
    "Scripts are in the \"integrated_model_scripts\" directory.\n",
    "\n",
    "**(1) daily_scoring.py**\n",
    "\n",
    "Daily scoring simulates sending data to the model API for scoring. Data is read in, sent to the Domino Model API, and predictions are returned. Domino's Prediction Capture Client captures the scoring data and model predictions. Every 24 hours, the captured data is ingested into the Drift Monitoring dashboard. Note that while this example uses a batch job, integrated model APIs capture both batch and real time data sent to the API.\n",
    "\n",
    "**(2) daily_ground_truth.py**\n",
    "\n",
    "Daily ground truth simulates uploading actual outcomes after the predictions have been made. A scheduled Domino Job writes the latest ground truth labels to an s3 bucket, then calls the Domino Model Monitoring API with the path to the file with the latest ground truth labels.\n",
    "\n",
    "If you schedule these two jobs, be sure that ground truth runs after the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e51e26-0ef1-44ea-a36e-66a01cf5af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample scoring dataset for External DMM Example\n",
    "\n",
    "# import uuid\n",
    "\n",
    "# score_df = training_df.sample(n=20)\n",
    "# score_df = score_df.drop('variety', axis=1)\n",
    "\n",
    "# ids = []\n",
    "\n",
    "# for i, row in score_df.iterrows():\n",
    "#     event_id = uuid.uuid4()\n",
    "#     ids.append(event_id)\n",
    "\n",
    "# # print(ids)\n",
    "# score_df['id'] = ids\n",
    "\n",
    "# score_df.to_csv(\"data/iris_score_data.csv\", index_label=False)"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
