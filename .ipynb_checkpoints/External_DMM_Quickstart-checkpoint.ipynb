{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c01e6a6-9c77-473d-a1f5-d7e2f427df76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample External Model with Domino Model Monitoring\n",
    "\n",
    "Example notebook to set up external Domino Model Monitoring (DMM):\n",
    "- Models hosted outside of Domino \n",
    "- Batch inference models scored using through Domino Jobs\n",
    "\n",
    "## Background\n",
    "The key difference between monitoring external models and Domino's integrated model monitoring is that with external models, Domino does not capture your model's training data using TrainingSets or prediction data through the DataCaptureClient. You will need to provide the model's training data, prediction data and, optionally, ground truth labels in a Monitoring Data Source, and then point your model in DMM to that data.\n",
    "\n",
    "Other notes:\n",
    "\n",
    "(1) The model does not need to be trained in Domino. It can be an existing model trained elsewhere.\n",
    "\n",
    "(2) It does not matter where the external model is hosted. It could be on an edge device, on-prem, in your cloud hosting service, or even hosted in Domino.\n",
    "\n",
    "The steps below can be done via the DMM UI, or automated using DMM's API. To use the UI, follow the steps documented here:\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/679cc1/set-up-model-monitor/\n",
    "\n",
    "The examples below demonstrate the setup & monitoring of external models using DMM's API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1b6d-ecce-4c7b-8281-9a71a3495707",
   "metadata": {},
   "source": [
    "### Step 1: Connect a Monitoring Data Source\n",
    "\n",
    "Domino requires an external data source to register an external model. For integrated models, you only need a Monitoring Data Source if you are ingesting ground truth labels.\n",
    "\n",
    "The external data source stores:\n",
    "\n",
    "(1) The training dataset\n",
    "\n",
    "(2) Prediction data & model predictions\n",
    "\n",
    "(3) Ground truth labels (optional)\n",
    "\n",
    "One Monitoring Data Source can be used for multiple DMM models. The same Monitoring Data Source can also be used for both ground truth labels for integrated models and data used for external models.\n",
    "\n",
    "The Monitoring Data Sources are registered independently of the data sources used in Domino Workbench. Model monitoring can read in data from multiple cloud data sources or on-prem data sources. A list of available Monitoring Data Sources is here:\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/8c7833/connect-a-data-source/\n",
    "\n",
    "You can register your Monitoring Data Source through the DMM UI or using DMM's API (see example API call below). If using the example below, be sure to update inputs 1-4 (labeled \"UPDATE\"), and the datasource type specific to your DMM data source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ffd2be1-4a18-420e-945d-d319442a5547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Datasource with name New_DataSource and type s3 is already registered.'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Example: Register a Monitoring Data Source using the the API.\n",
    "\n",
    "# API Reference: https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_datasource\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key \n",
    "# https://docs.dominodatalab.com/en/latest/user_guide/40b91f/domino-api-authentication/#_authenticate_with_an_api_key)\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (3) Your new DMM datasource name\n",
    "datasource_name = 'New_DataSource'\n",
    "\n",
    "# UPDATE: (4) DMM Datasource Type & Attributes. These credentials will be different for each datasource.\n",
    "# This example is for AWS s3, other data sources are documented here: \n",
    "# https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_dataSourceRequestCommon\n",
    "\n",
    "datasource_type = \"s3\"\n",
    "S3_Bucket_Name = \"se-demo-bucket\"\n",
    "S3_Region = \"us-west-2\"\n",
    "AWS_Access_Key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_Secret_Key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "datasource_url = \"https://{}/model-monitor/v2/api/datasource\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "data_source_request = {\n",
    "    \"name\": datasource_name,\n",
    "    \"type\": datasource_type,\n",
    "    \"config\" : {\n",
    "        \"bucket\": S3_Bucket_Name,\n",
    "        \"region\": S3_Region,\n",
    "        \"instance_role\" : False,\n",
    "        \"access_key\": AWS_Access_Key,\n",
    "        \"secret_key\": AWS_Secret_Key\n",
    "    }\n",
    "}\n",
    "# format(datasource_name, datasource_type, S3_Bucket_Name, S3_Region, AWS_Access_Key, AWS_Secret_Key)\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(data_source_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2db7f-89b7-4646-92d7-6aae3bf69315",
   "metadata": {},
   "source": [
    "### 2. Register an External Model\n",
    "\n",
    "Once you have a Monitoring Data Source registered:\n",
    "\n",
    "(1) Upload the training data used for your model to that Monitoring Data Source, and note the path to your training data file. DMM will need this to initiate the model.\n",
    "\n",
    "(2) Prepare your **Monitoring Config JSON** file. In the UI, the config json looks like the example below.\n",
    "\n",
    "It contains 3 components:\n",
    "\n",
    "(A) **variables**: A list of variable names, data types, and variable types for each column that you want to monitor. This can include the target variable if you'd like to monitor drift in your model's predictions.\n",
    "\n",
    "(B) **datasetDetails**: The name and location of your training dataset that you just uploaded into the DMM datasource\n",
    "\n",
    "(C) **modelMetadata**: The name and description of your model to render in Domino Model Monitoring\n",
    "\n",
    "Like with DMM Data Sources, Monitoring Config JSONs can be copied and pasted into the UI or automatically sent to Domino via APIs. Full documentation for Monitoring Config JSONs here:\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/bb88ca/monitoring-config-json/\n",
    "\n",
    "**Pro Tip:** Domino recommends saving your config json as a file in your Project files for future reference and modification. See \"Example_Model_Config.json\"\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\",\n",
    "            \"name\": \"variety\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": \"iris.csv\",\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": \"iris.csv\",\n",
    "            \"fileFormat\": \"csv\"\n",
    "        },\n",
    "        \"datasourceName\": \"dmm-shared-bucket\",\n",
    "        \"datasourceType\": \"s3\"\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"iris_model\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.01\",\n",
    "        \"description\": \"classification_iris_model\",\n",
    "        \"author\": \"John Doe\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cef27f-7154-4f0c-95d8-fdce267aa768",
   "metadata": {},
   "source": [
    "### Link the Monitoring Data Source to this Project (Optional)\n",
    "\n",
    "Data sources are registered separately in Domino Model Monitoring and Domino's workbench. \n",
    "\n",
    "In this example, we want to attach the same external data source (such as an s3 bucket) to both DMM and Domino's Workbench, since we are uploading the training data from Domino's Workbench. You don't have to do it from here though, you can add your training data directly to your DMM datasource outside of Domino.\n",
    "\n",
    "To upload the training dataset from the Workbench, add the same Monitoring Data Source registered above to this project. In a workspace, you can add it through the Data tab on the left.\n",
    "\n",
    "The Iris training dataset is already saved in the \"data\" folder in the mnt directory as \"iris_training_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb239005-e12e-4263-8953-fabbce339a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "       variety  \n",
       "130  virginica  \n",
       "131  virginica  \n",
       "132  virginica  \n",
       "133  virginica  \n",
       "134  virginica  \n",
       "135  virginica  \n",
       "136  virginica  \n",
       "137  virginica  \n",
       "138  virginica  \n",
       "139  virginica  \n",
       "140  virginica  \n",
       "141  virginica  \n",
       "142  virginica  \n",
       "143  virginica  \n",
       "144  virginica  \n",
       "145  virginica  \n",
       "146  virginica  \n",
       "147  virginica  \n",
       "148  virginica  \n",
       "149  virginica  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# import pandas as pd\n",
    "\n",
    "# data = load_iris()\n",
    "# target_column_name = \"variety\"\n",
    "\n",
    "# training_df = pd.DataFrame(data['data'], columns = data.feature_names)\n",
    "# training_df['variety'] = [data.target_names[y] for y in data[\"target\"]]\n",
    "# training_df.tail(20)\n",
    "# training_df.to_csv('/mnt/code/data/iris_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8819e79-9275-4052-9dd3-bfc4db9afc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Training Data from Domino Workbench to the DMM data source\n",
    "\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "# The name of the DMM data source in Domino's Workbench.\n",
    "external_datasource = \"demo-bucket\" # UPDATE \n",
    "\n",
    "# instantiate a client and fetch the datasource instance\n",
    "object_store = DataSourceClient().get_datasource(\"{}\".format(external_datasource))\n",
    "\n",
    "# Upload the existing training data to your DMM datasource from the Workbench\n",
    "object_store.upload_file('iris_training_data.csv', '/mnt/code/data/iris_training_data.csv')\n",
    "object_store.upload_file('external_model_scoring_data.csv', '/mnt/code/data/external_model_scoring_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76e734ab-55b4-4136-94ac-b959465c3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"662967dff19b7cc360c275ac\", \"createdAt\": 1713989599, \"updatedAt\": 1713989599, \"name\": \"Example External Model\", \"description\": \"classification_iris_model\", \"modelType\": \"classification\", \"author\": \"John Doe\", \"version\": \"1.01\", \"userId\": \"4b684539-9bd4-46d4-bb64-60c8094ccb15\", \"isDeleted\": false, \"ingestionStatus\": \"created\", \"registrationStatus\": \"created\", \"sourceType\": \"standalone\", \"visibility\": \"public\", \"collaborators\": [], \"tagIds\": []}'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#### Example to register a model via the API\n",
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (3) Your DMM datasource name\n",
    "datasource_name = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (5) DMM Datasource Type & Attributes. These file names & format will be different for each datasource.\n",
    "training_dataset_name = \"iris_training_data.csv\"\n",
    "training_dataset_path = \"iris_training_data.csv\"\n",
    "training_dataset_fileFormat = \"csv\"\n",
    "\n",
    "datasource_url = \"https://{}/model-monitor/v2/api/model\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "model_register_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal length (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal length (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal width (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal width (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\",\n",
    "            \"name\": \"variety\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": training_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": training_dataset_path,\n",
    "            \"fileFormat\": training_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"Example External Model\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.01\",\n",
    "        \"description\": \"classification_iris_model\",\n",
    "        \"author\": \"John Doe\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(model_register_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    "\n",
    "print(\"New model id is:\")\n",
    "\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2909a-85cc-4c80-9db3-28a77867e22b",
   "metadata": {},
   "source": [
    "### 3. Set up Drift Detection\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/86bc1f/set-up-drift-detection/\n",
    "\n",
    "\n",
    "While integrated models can capture prediction data using the DataCaptureClient, external models need to ingest prediction data from a connected Monitoring Data Source. Just like with the initial model registration, information needed to ingest the prediction data is provided to Domino using a **Prediction Config JSON**.\n",
    "\n",
    "\n",
    "There are two approaches to automating prediction data ingest from a Monitoring Data Source:\n",
    "\n",
    "\n",
    "(1) Append new data to the same file in your Monitoring Data Source.\n",
    "\n",
    "\n",
    "  -  Only register your Prediction Data config with the path to the prediction data file once. Domino will automatically retrieve new data every 24 hours from that file. You can schedule the daily check in the DMM UI.\n",
    "  -  This approach requires registering a **timestamp** variable so that DMM knows which prediction rows are new.\n",
    "\n",
    "\n",
    "(2) Upload prediction data as separate files to your Monitoring Data Source.\n",
    "\n",
    "\n",
    "  - This requires updating the datasetDetails in the Prediction Data Config everytime new prediction data is added. This is best automated through the API, using a Domino Job or some other scheduler.\n",
    "  - When you update the Prediction Data Config, only update the \"datasetDetails\" with the new prediction data file path. Variables are only set the first time, if you re-register variable names DMM will throw an error.\n",
    "\n",
    "\n",
    "Below is an example of an initial Prediction Data Config file, which be copied and pasted into the UI or automatically sent to Domino via APIs. Full docs here:\n",
    "\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/bb88ca/monitoring-config-json/\n",
    "\n",
    "\n",
    "At the end is an example of only updating the \"datasetDetails\" via the API if you choose to follow approach #2.\n",
    "\n",
    "**Pro Tip:** Domino recommends saing your config json as a file in your Project files for future reference and modification. See \"Example_Prediction_Config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "854c970b-34b5-4747-8d10-a982f80a0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[\"Dataset already registered with the model.\"]'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "### Example to register the initial Prediction Config via the API\n",
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID, created when the model was registered in Step 2.\n",
    "model_id='66295e50965e21e5b0d56b84'\n",
    "\n",
    "# UPDATE: (3) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource name\n",
    "datasource_name = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (5) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (6) Your RowID Name (Optional, for model quality monitoring. Do this only once.)\n",
    "Prediction_ID_name = 'id'\n",
    "\n",
    "# UPDATE: (7) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "prediction_dataset_name = \"external_model_scoring_data.csv\"\n",
    "prediction_dataset_path = \"external_model_scoring_data.csv\"\n",
    "prediction_dataset_fileFormat = \"csv\"\n",
    "\n",
    "prediction_data_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/prediction\".format(your_domino_url, model_id)\n",
    "\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "prediction_registration_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"string\",\n",
    "            \"variableType\": \"row_identifier\",\n",
    "            \"name\": Prediction_ID_name\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": prediction_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": prediction_dataset_path,\n",
    "            \"fileFormat\": prediction_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", prediction_data_url, headers=headers, data = json.dumps(prediction_registration_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3224387-ecdc-419f-b523-bb3a0d783b13",
   "metadata": {},
   "source": [
    "#### Option 2: Upload additional prediction data as separate files to your Monitoring Data Source.\n",
    "\n",
    "Next is an example for updating the prediction data file via the API if you choose option (2).\n",
    "\n",
    "Example scripts to automate these steps using Domino Jobs are in the \"external_model_scripts\" folder.\n",
    "\n",
    "**domino_batch_job.py** simulates the external model scoring step, using a Domino job for batch inference. Batch inference in Domino using Domino Jobs can be monitored the same way as an external model. For external models, the scoring data, external model predictions, and prediction ID must be captured manually.\n",
    "\n",
    "**daily_scoring_upload.py** \n",
    "\n",
    "1) First, the script uploads the scoring data, including the external model predictions and prediction ID, to the DMM data source for our external model. \n",
    "2) Next, it uploads a csv file containing the ground truth labels to the DMM data source.\n",
    "3) Finally it updates the file paths for both scoring data and ground truth data using the DMM API so that DMM can find the new data when it ingests data from the DMM data source. \n",
    "\n",
    "To test these scripts, the ensure batch job runs before daily scoring, and that DMM is scheduled to ingest the scoring and ground truth data after daily_scoring_upload has finished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc6736-63a0-46d2-8d0e-fb1beb462bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example to update Prediction Config if uploading prediction data as separate files to your Monitoring Data Source.\n",
    "# Only update the \"datasetDetails\". You could run this snippet as a Domino Job, updating the prediction dataset name and path.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# Your Model Monitoring Model ID, created when the model was registered in Step 2.\n",
    "model_id='6628103c965e21e5b0d56b29'\n",
    "\n",
    "# Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# Your DMM datasource name\n",
    "datasource_name = 'se-demo-bucket'\n",
    "\n",
    "# Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# The updated path to your prediction dataset\n",
    "prediction_dataset_name = \"iris_ground_truth_1_25_2024.csv\"\n",
    "prediction_dataset_path = \"iris_ground_truth_1_25_2024.csv\"\n",
    "prediction_dataset_fileFormat = \"csv\"\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "prediction_registration_request = {\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": prediction_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": prediction_dataset_path,\n",
    "            \"fileFormat\": prediction_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", prediction_data_url, headers=headers, data = json.dumps(prediction_registration_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a23c65-10c7-4217-80ab-1848f7a50b8a",
   "metadata": {},
   "source": [
    "### 4. Set up Model Quality Monitoring (Optional)\n",
    "\n",
    "There is very little difference in setting up Model Quality Monitoring between Internal and External models, since Domino Model APIs cannot capture actual outcomes after-the-fact. The process is nearly the same as registering prediction data for external models.\n",
    "\n",
    "Typically for this step you would fetch actual ground truth data (the actual outcomes from what your model predicted on), \n",
    "join the actual outcomes with your prediction data, and upload into a Monitoring Data Source for Model Quality \n",
    "analysis.\n",
    "\n",
    "However, for purposes of creating a quick demo, we'll make up some fake ground truth data using the data we used in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17981520-45e2-4c06-9b06-6088bffeb897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Navigate to the most recent predictions and copy the file path to one of the parquet files in there. \n",
    "# This is where you can find data captured by the Data Capture Client in your Model API\n",
    "\n",
    "# /mnt/data/prediction_data/{PREDICTION_DATA_ID}/{DATE}/{TIME}/predictions_{ID}.parquet\n",
    "\n",
    "path = '/mnt/data/prediction_data/65b04f6b1266902edb95b260/$$date$$=2024-04-23Z/$$hour$$=07Z/predictions_96f154f9-99c3-4da0-ae7c-878b21ddffa7.parquet'\n",
    "\n",
    "predictions = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36478b4f-53de-4a11-879e-b7a82875a892",
   "metadata": {},
   "source": [
    "The Ground Truth dataset needs 2 columns: \n",
    "\n",
    "1) The existing event ID column from the model predictions.\n",
    "   \n",
    "    This column has the join keys for joing ground truth lables to your model's predictions\n",
    "\n",
    "3) Your new column containing ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abbad2-3785-4cc8-b10c-608bc82ecfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_id = predictions['event_id']\n",
    "iris_ground_truth = predictions['variety']\n",
    "\n",
    "# Create a new dataframe\n",
    "ground_truth = pd.DataFrame(columns=['event_id', 'iris_ground_truth'])\n",
    "ground_truth['event_id'] = event_id\n",
    "ground_truth['iris_ground_truth'] = iris_ground_truth\n",
    "\n",
    "# These row labels help find some diferent iris types in our initial scoring data\n",
    "end_index = predictions.shape[0]\n",
    "mid_index = int(round(predictions.shape[0] / 2, 0))\n",
    "\n",
    "# Simulate some classifcation errors. This makes our confusion matrix interesting.\n",
    "ground_truth.iloc[0, 1] = 'virginica'\n",
    "ground_truth.iloc[1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index-1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index, 1] = 'virginica'\n",
    "ground_truth.iloc[end_index-2, 1] = 'setosa'\n",
    "ground_truth.iloc[end_index-1, 1] = 'setosa'\n",
    "\n",
    "# Save this example ground truth csv to your file to your Project files for reference.\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day\n",
    "year = date.year\n",
    "\n",
    "date = str(datetime.datetime.today()).split()[0]\n",
    "\n",
    "ground_truth.to_csv('data/iris_ground_truth_{}_{}_{}.csv'.format(month, day, year), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e75973-c2f9-429e-aa4e-b8b1c029aaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    " \n",
    "# UPDATE: (1) The name of your monitoring data source in Domino Model Monitoring\n",
    "data_source = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID (NOT Model API model ID)\n",
    "model_id='65b0525c54ac3acc8cb495d1'\n",
    "\n",
    "# UPDATE: (3) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    " \n",
    "# UPDATE: (4) The name of the file uploaded to s3 above\n",
    "gt_file_name = \"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year)\n",
    "\n",
    "# UPDATE: (5) Ground Truth column name\n",
    "GT_column_name = 'iris_ground_truth'\n",
    "\n",
    "# UPDATE: (6) Your original target column name\n",
    "target_column_name = 'variety'\n",
    "\n",
    "# UPDATE: (7) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (8) Your DataSource Type\n",
    "datasource_type = \"s3\"\n",
    "\n",
    "ground_truth_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(your_domino_url, model_id)\n",
    "\n",
    "print('Registering {} From S3 Bucket in DMM'.format(gt_file_name))\n",
    " \n",
    "# create GT payload    \n",
    " \n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    " \n",
    "ground_truth_payload = \"\"\"\n",
    "{{\n",
    "    \"variables\": [{{\n",
    "    \n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"ground_truth\",\n",
    "            \"name\": \"{2}\", \n",
    "            \"forPredictionOutput\": \"{3}\"\n",
    "        \n",
    "    }}],\n",
    "    \"datasetDetails\": {{\n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"{4}\"\n",
    "        }}\n",
    "}}\n",
    "\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name, datasource_type)\n",
    " \n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", ground_truth_url, headers=headers, data = ground_truth_payload)\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc660f-f094-4b83-bc2a-935b835e9c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "Going forward, Domino will automatically capture all prediction data going across your Model API. It will ingest these predictions for Drift detection once per day. You can set a schedule to determine when this ingest happens.\n",
    "\n",
    "To periodically upload ground truth labels, repeat the previous step, but without the “variables” in the ground truth payload (this only needs to be done once). As new ground truth labels are added, point Domino to the path to the new labels in the monitoring data source by pinging the same Model Monitoring API:\n",
    "\n",
    "ground_truth_payload = \"\"\"\n",
    "\n",
    "{{\n",
    "\n",
    "       \"datasetDetails\": {{\n",
    "        \n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"s3\"\n",
    "        }}\n",
    "}}\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd486-42bb-48e7-85e5-2d4ed3056f18",
   "metadata": {},
   "source": [
    "### Automation with Domino Jobs\n",
    "To simulate Domino Model Monitoring over time, you can try out running the following two scripts as scheduled Domino Jobs:\n",
    "\n",
    "**(1) daily_scoring.py**\n",
    "\n",
    "Daily scoring simulates a daily batch scoring script. Data is read in, sent to the Domino Model API, and predictions are returned.\n",
    "Domino's Prediction Capture Client captures this scoring data, and every 24 hours, it gets ingested into the Drift Monitoring dashboard.\n",
    "\n",
    "**(2) daily_ground_truth.py**\n",
    "\n",
    "Daily ground truth simulates uploading actual outcomes after the predictions have been made. A scheduled Domino Job writes the latest ground truth labels to an s3 bucket, then calls the Domino Model Monitoring API with the path to the file with the latest ground truth labels.\n",
    "\n",
    "If you schedule these two jobs, be sure that ground truth runs after the predictions!"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
